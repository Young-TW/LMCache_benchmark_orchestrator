import argparse
import time
import requests
import statistics
import tomli_w
from datetime import datetime
from openai import OpenAI

# æ¸¬è©¦ç”¨çš„ Prompt (è¶³å¤ é•·ä»¥è§¸ç™¼ Cache æ•ˆæœ)
LONG_PROMPT = "You are an AI assistant. Please generate a very detailed report about the history of GPU architecture development from 2000 to 2025, focusing on parallel computing improvements." * 5

def measure_request(client, model_name, prompt, max_tokens=20):
    start_time = time.time()
    ttft = 0
    first_token_time = 0

    try:
        stream = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=0,
            stream=True
        )

        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                if first_token_time == 0:
                    first_token_time = time.time()
                    ttft = first_token_time - start_time

        total_time = time.time() - start_time
        return {"ttft": ttft, "total": total_time, "success": True}
    except Exception as e:
        print(f"Request failed: {e}")
        return {"ttft": 0, "total": 0, "success": False, "error": str(e)}

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--test-id", required=True)
    parser.add_argument("--producers", default="")
    parser.add_argument("--consumers", required=True)
    args = parser.parse_args()

    # è§£æ URLs
    producer_urls = [u for u in args.producers.split(",") if u]
    consumer_urls = [u for u in args.consumers.split(",") if u]

    results = {
        "id": args.test_id,
        "timestamp": datetime.now().isoformat(),
        "config": {
            "producer_count": len(producer_urls),
            "consumer_count": len(consumer_urls)
        },
        "metrics": {}
    }

    # å–å¾—æ¨¡å‹åç¨± (å‡è¨­ç¬¬ä¸€å€‹ Consumer å¯ç”¨)
    try:
        temp_client = OpenAI(base_url=consumer_urls[0], api_key="EMPTY")
        model_list = temp_client.models.list()
        model_name = model_list.data[0].id
    except:
        model_name = "unknown"

    print(f"\n--- é–‹å§‹æ¸¬è©¦ ID: {args.test_id} ---")
    print(f"Producers: {len(producer_urls)}, Consumers: {len(consumer_urls)}")

    # æ¨¡å¼ A: Disaggregated (æœ‰ Producer ä¹Ÿæœ‰ Consumer)
    if producer_urls:
        print(">> Mode: Disaggregated (LMCache)")

        # 1. Hit Producer (Prefill + Store Cache)
        p_client = OpenAI(base_url=producer_urls[0], api_key="EMPTY") # ç°¡å–®èµ·è¦‹åªæ‰“ç¬¬ä¸€å€‹ Producer
        print("Step 1: è«‹æ±‚ Producer (Prefill)...")
        p_res = measure_request(p_client, model_name, LONG_PROMPT)
        results["metrics"]["producer_prefill"] = p_res
        print(f"Producer TTFT: {p_res['ttft']:.4f}s")

        time.sleep(2) # ç­‰å¾…å‚³è¼¸

        # 2. Hit Consumer (Decode + Load Cache)
        # æˆ‘å€‘æ¸¬è©¦ã€Œæ‰€æœ‰ã€Consumer çœ‹çœ‹æ˜¯å¦éƒ½èƒ½åƒåˆ° Cache
        c_results = []
        print("Step 2: è«‹æ±‚ Consumers (Cache Hit check)...")
        for i, c_url in enumerate(consumer_urls):
            c_client = OpenAI(base_url=c_url, api_key="EMPTY")
            print(f"  Testing Consumer {i} ({c_url})...")
            res = measure_request(c_client, model_name, LONG_PROMPT)
            c_results.append(res)
            print(f"  Consumer {i} TTFT: {res['ttft']:.4f}s")

        # è¨ˆç®— Consumer å¹³å‡å€¼
        avg_c_ttft = statistics.mean([r['ttft'] for r in c_results if r['success']])
        results["metrics"]["consumer_avg_ttft"] = avg_c_ttft
        results["metrics"]["consumers_detail"] = c_results

        # Speedup Ratio
        if avg_c_ttft > 0:
            speedup = p_res['ttft'] / avg_c_ttft
            results["metrics"]["speedup_ratio"] = speedup
            print(f"ğŸš€ Speedup Ratio: {speedup:.2f}x")

    # æ¨¡å¼ B: Standalone / TP8 (åªæœ‰ Consumer/Main node)
    else:
        print(">> Mode: Standalone (Baseline)")
        c_client = OpenAI(base_url=consumer_urls[0], api_key="EMPTY")
        print("Step 1: è«‹æ±‚ Standalone Node...")
        res = measure_request(c_client, model_name, LONG_PROMPT)
        results["metrics"]["baseline_run1"] = res
        print(f"Baseline TTFT: {res['ttft']:.4f}s")

        # å†è·‘ä¸€æ¬¡çœ‹çœ‹ vLLM å…§å»ºçš„ Prefix Caching (å¦‚æœæœ‰çš„è©±)
        print("Step 2: å†æ¬¡è«‹æ±‚ (Check local cache)...")
        res2 = measure_request(c_client, model_name, LONG_PROMPT)
        results["metrics"]["baseline_run2"] = res2
        print(f"Baseline (2nd run) TTFT: {res2['ttft']:.4f}s")

    # å„²å­˜çµæœ
    outfile = f"report_{args.test_id}.toml"
    with open(outfile, "wb") as f:
        tomli_w.dump(results, f)
    print(f"å ±å‘Šå·²å„²å­˜è‡³ {outfile}")

if __name__ == "__main__":
    main()
